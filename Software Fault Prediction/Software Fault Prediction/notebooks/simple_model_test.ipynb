{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d45e07a",
   "metadata": {},
   "source": [
    "# Simple Model Testing\n",
    "Upload your trained model and test dataset to calculate F1-score and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b724cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install scikit-learn pandas numpy deap imbalanced-learn openpyxl joblib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff68802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "import joblib\n",
    "from google.colab import files\n",
    "\n",
    "# Optional imports with fallbacks\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "except ImportError:\n",
    "    print(\"Warning: imbalanced-learn not available\")\n",
    "    \n",
    "try:\n",
    "    from deap import base, creator, tools, algorithms\n",
    "except ImportError:\n",
    "    print(\"Warning: deap not available\")\n",
    "    \n",
    "try:\n",
    "    from scipy.io import arff\n",
    "except ImportError:\n",
    "    print(\"Warning: scipy not available for ARFF files\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your trained model (.pkl file)\n",
    "print(\"Upload your trained model (.pkl file):\")\n",
    "uploaded_model = files.upload()\n",
    "model_filename = list(uploaded_model.keys())[0]\n",
    "\n",
    "# Load the model (handle both simple models and complex model_info dictionaries)\n",
    "try:\n",
    "    # Try loading with joblib first (preferred method from your training code)\n",
    "    model_data = joblib.load(model_filename)\n",
    "    \n",
    "    if isinstance(model_data, dict) and 'model' in model_data:\n",
    "        # Complex model info dictionary from your training code\n",
    "        model = model_data['model']\n",
    "        selected_features = model_data.get('selected_feature_indices', None)\n",
    "        scaler_from_model = model_data.get('scaler', None)\n",
    "        print(f\"Loaded complex model with metadata from '{model_filename}'\")\n",
    "        print(f\"Selected features: {len(selected_features) if selected_features else 'All'}\")\n",
    "    else:\n",
    "        # Simple model object\n",
    "        model = model_data\n",
    "        selected_features = None\n",
    "        scaler_from_model = None\n",
    "        print(f\"Loaded simple model from '{model_filename}'\")\n",
    "        \n",
    "except:\n",
    "    # Fallback to pickle if joblib fails\n",
    "    with open(model_filename, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    if isinstance(model_data, dict) and 'model' in model_data:\n",
    "        model = model_data['model']\n",
    "        selected_features = model_data.get('selected_feature_indices', None)\n",
    "        scaler_from_model = model_data.get('scaler', None)\n",
    "    else:\n",
    "        model = model_data\n",
    "        selected_features = None\n",
    "        scaler_from_model = None\n",
    "    \n",
    "    print(f\"Model '{model_filename}' loaded successfully with pickle!\")\n",
    "\n",
    "print(f\"Model type: {type(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd03058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your test dataset\n",
    "print(\"Upload your test dataset (.csv, .xlsx, or .arff):\")\n",
    "uploaded_data = files.upload()\n",
    "data_filename = list(uploaded_data.keys())[0]\n",
    "\n",
    "# Load the dataset\n",
    "if data_filename.endswith('.csv'):\n",
    "    df = pd.read_csv(data_filename)\n",
    "elif data_filename.endswith('.xlsx'):\n",
    "    df = pd.read_excel(data_filename)\n",
    "elif data_filename.endswith('.arff'):\n",
    "    from scipy.io import arff\n",
    "    data, meta = arff.loadarff(data_filename)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Dataset '{data_filename}' loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba088da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Assume the last column is the target variable\n",
    "X_test = df.iloc[:, :-1]\n",
    "y_test = df.iloc[:, -1]\n",
    "\n",
    "# Convert categorical target to numeric if needed\n",
    "if y_test.dtype == 'object':\n",
    "    y_test = pd.Categorical(y_test).codes\n",
    "\n",
    "# Use the model's saved scaler if available, otherwise create new one\n",
    "if scaler_from_model is not None:\n",
    "    print(\"Using scaler from saved model\")\n",
    "    X_test_scaled = scaler_from_model.transform(X_test)\n",
    "else:\n",
    "    print(\"Creating new scaler for features\")\n",
    "    scaler = StandardScaler()\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Apply feature selection if the model was trained with specific features\n",
    "if selected_features is not None:\n",
    "    print(f\"Applying feature selection: {len(selected_features)} out of {X_test_scaled.shape[1]} features\")\n",
    "    X_test_scaled = X_test_scaled[:, selected_features]\n",
    "else:\n",
    "    print(\"Using all features\")\n",
    "\n",
    "print(f\"Final test features shape: {X_test_scaled.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL PERFORMANCE RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
